#!/usr/bin/env python3
"""
å…³é”®å­—è¯†åˆ«è„šæœ¬ - åœ¨è½¬å½•æ–‡æœ¬ä¸­æŸ¥æ‰¾å…³é”®å­—å¹¶å®šä½æ—¶é—´æˆ³
"""

import json
import sys
import re
from pathlib import Path

def load_keywords(config_file):
    """åŠ è½½å…³é”®å­—é…ç½®æ–‡ä»¶"""
    with open(config_file, 'r', encoding='utf-8') as f:
        config = json.load(f)
    return config.get('keywords', [])

def find_keyword_positions(transcript_data, keywords):
    """
    åœ¨è½¬å½•æ–‡æœ¬ä¸­æŸ¥æ‰¾å…³é”®å­—ä½ç½®

    Args:
        transcript_data: è½¬å½•æ•°æ®ï¼ˆåŒ…å« chars æ•°ç»„ï¼‰
        keywords: å…³é”®å­—åˆ—è¡¨

    Returns:
        åŒ¹é…ç»“æœåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« keyword, start, end, context
    """
    full_text = transcript_data['full_text']
    chars = transcript_data['chars']
    matches = []

    print(f"ğŸ” å¼€å§‹æœç´¢å…³é”®å­—...")
    print(f"   æ–‡æœ¬é•¿åº¦: {len(full_text)} å­—ç¬¦")
    print(f"   å…³é”®å­—æ•°é‡: {len(keywords)}")

    for keyword in keywords:
        # åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…ä½ç½®
        pattern = re.escape(keyword)
        for match in re.finditer(pattern, full_text):
            start_idx = match.start()
            end_idx = match.end()

            # è·å–æ—¶é—´æˆ³
            if start_idx < len(chars) and end_idx <= len(chars):
                start_time = chars[start_idx]['start']
                end_time = chars[end_idx - 1]['end']

                # è·å–ä¸Šä¸‹æ–‡ï¼ˆå‰åå„10ä¸ªå­—ç¬¦ï¼‰
                context_start = max(0, start_idx - 10)
                context_end = min(len(full_text), end_idx + 10)
                context = full_text[context_start:context_end]

                matches.append({
                    'keyword': keyword,
                    'start': start_time,
                    'end': end_time,
                    'position': start_idx,
                    'context': context,
                    'matched_text': full_text[start_idx:end_idx]
                })

                print(f"   âœ“ æ‰¾åˆ° '{keyword}' åœ¨ {start_time:.2f}s-{end_time:.2f}s")

    print(f"âœ… æœç´¢å®Œæˆï¼Œå…±æ‰¾åˆ° {len(matches)} å¤„åŒ¹é…")
    return matches

def generate_delete_plan(matches, buffer_before=0.5, buffer_after=0.5):
    """
    ç”Ÿæˆåˆ é™¤è®¡åˆ’ï¼ˆåˆå¹¶é‡å çš„æ—¶é—´æ®µï¼‰

    Args:
        matches: åŒ¹é…ç»“æœåˆ—è¡¨
        buffer_before: å‰ç½®ç¼“å†²æ—¶é—´ï¼ˆç§’ï¼‰
        buffer_after: åç½®ç¼“å†²æ—¶é—´ï¼ˆç§’ï¼‰

    Returns:
        åˆ é™¤ç‰‡æ®µåˆ—è¡¨ [(start, end), ...]
    """
    if not matches:
        return []

    # æ·»åŠ ç¼“å†²æ—¶é—´
    segments = []
    for m in matches:
        start = max(0, m['start'] - buffer_before)
        end = m['end'] + buffer_after
        segments.append((start, end))

    # æŒ‰å¼€å§‹æ—¶é—´æ’åº
    segments.sort()

    # åˆå¹¶é‡å çš„ç‰‡æ®µ
    merged = [segments[0]]
    for current in segments[1:]:
        last = merged[-1]
        if current[0] <= last[1]:  # æœ‰é‡å 
            merged[-1] = (last[0], max(last[1], current[1]))
        else:
            merged.append(current)

    return merged
