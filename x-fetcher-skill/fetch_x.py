#!/usr/bin/env python3
"""
X (Twitter) å¸–å­å†…å®¹æŠ“å–å·¥å…·
æ”¯æŒæ™®é€šæ¨æ–‡å’Œ X Article é•¿æ–‡ç« 
ç”¨æ³•: python fetch_x.py <x_url> [--save-md]
"""

import sys
import re
import json
import os
from datetime import datetime
import requests
from urllib.parse import urlparse

def extract_tweet_id(url):
    """ä» URL æå– tweet ID"""
    patterns = [
        r'(?:x\.com|twitter\.com)/\w+/status/(\d+)',
        r'(?:x\.com|twitter\.com)/\w+/statuses/(\d+)',
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None

def extract_username(url):
    """ä» URL æå–ç”¨æˆ·å"""
    match = re.search(r'(?:x\.com|twitter\.com)/(\w+)/status', url)
    return match.group(1) if match else None

def fetch_via_fxtwitter(url):
    """é€šè¿‡ fxtwitter API è·å–å†…å®¹"""
    api_url = re.sub(r'(x\.com|twitter\.com)', 'api.fxtwitter.com', url)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    }
    try:
        resp = requests.get(api_url, headers=headers, timeout=15)
        if resp.status_code == 200:
            return resp.json()
    except Exception as e:
        print(f"  fxtwitter é”™è¯¯: {e}", file=sys.stderr)
    return None

def fetch_via_syndication(tweet_id):
    """é€šè¿‡ X çš„ syndication API è·å–å†…å®¹"""
    url = f"https://cdn.syndication.twimg.com/tweet-result?id={tweet_id}&token=0"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    }
    try:
        resp = requests.get(url, headers=headers, timeout=10)
        if resp.status_code == 200:
            return resp.json()
    except Exception as e:
        print(f"  syndication é”™è¯¯: {e}", file=sys.stderr)
    return None

def extract_article_content(article):
    """ä» X Article ä¸­æå–å®Œæ•´å†…å®¹"""
    if not article:
        return None

    content_blocks = article.get("content", {}).get("blocks", [])

    # æ‹¼æ¥æ‰€æœ‰æ–‡æœ¬å—
    paragraphs = []
    for block in content_blocks:
        text = block.get("text", "").strip()
        block_type = block.get("type", "unstyled")

        if text:
            # æ ¹æ®ç±»å‹æ·»åŠ æ ¼å¼
            if block_type == "header-one":
                paragraphs.append(f"# {text}")
            elif block_type == "header-two":
                paragraphs.append(f"## {text}")
            elif block_type == "header-three":
                paragraphs.append(f"### {text}")
            elif block_type == "blockquote":
                paragraphs.append(f"> {text}")
            elif block_type == "unordered-list-item":
                paragraphs.append(f"- {text}")
            elif block_type == "ordered-list-item":
                paragraphs.append(f"1. {text}")
            else:
                paragraphs.append(text)

    return "\n\n".join(paragraphs)

def format_output(data, source):
    """æ ¼å¼åŒ–è¾“å‡º"""
    result = {
        "source": source,
        "success": True,
        "type": "tweet",
        "content": {}
    }

    if source == "fxtwitter":
        tweet = data.get("tweet", {})
        article = tweet.get("article")

        if article:
            # X Article é•¿æ–‡ç« 
            result["type"] = "article"
            result["content"] = {
                "title": article.get("title", ""),
                "preview": article.get("preview_text", ""),
                "full_text": extract_article_content(article),
                "cover_image": article.get("cover_media", {}).get("media_info", {}).get("original_img_url"),
                "author": tweet.get("author", {}).get("name", ""),
                "username": tweet.get("author", {}).get("screen_name", ""),
                "created_at": article.get("created_at", ""),
                "modified_at": article.get("modified_at", ""),
                "likes": tweet.get("likes", 0),
                "retweets": tweet.get("retweets", 0),
                "views": tweet.get("views", 0),
                "bookmarks": tweet.get("bookmarks", 0)
            }
        else:
            # æ™®é€šæ¨æ–‡
            result["content"] = {
                "text": tweet.get("text", ""),
                "author": tweet.get("author", {}).get("name", ""),
                "username": tweet.get("author", {}).get("screen_name", ""),
                "created_at": tweet.get("created_at", ""),
                "likes": tweet.get("likes", 0),
                "retweets": tweet.get("retweets", 0),
                "views": tweet.get("views", 0),
                "media": [m.get("url") for m in tweet.get("media", {}).get("all", []) if m.get("url")],
                "replies": tweet.get("replies", 0)
            }

    elif source == "syndication":
        result["content"] = {
            "text": data.get("text", ""),
            "author": data.get("user", {}).get("name", ""),
            "username": data.get("user", {}).get("screen_name", ""),
            "created_at": data.get("created_at", ""),
            "likes": data.get("favorite_count", 0),
            "retweets": data.get("retweet_count", 0),
            "media": [m.get("media_url_https") for m in data.get("mediaDetails", []) if m.get("media_url_https")]
        }

    return result

def fetch_tweet(url):
    """ä¸»å‡½æ•°ï¼šå°è¯•å¤šç§æ–¹å¼è·å–å¸–å­å†…å®¹"""
    tweet_id = extract_tweet_id(url)
    username = extract_username(url)

    if not tweet_id:
        return {"success": False, "error": "æ— æ³•ä» URL æå– tweet ID"}, tweet_id, username

    print(f"ğŸ“ Tweet ID: {tweet_id}", file=sys.stderr)
    print(f"ğŸ“ Username: {username}", file=sys.stderr)
    print(f"ğŸ” æ­£åœ¨æŠ“å–...", file=sys.stderr)

    # æ–¹æ³•1: fxtwitter API (æ”¯æŒ Article)
    print("  å°è¯• fxtwitter API...", file=sys.stderr)
    data = fetch_via_fxtwitter(url)
    if data and data.get("tweet"):
        print("  âœ… fxtwitter æˆåŠŸ", file=sys.stderr)
        return format_output(data, "fxtwitter"), tweet_id, username

    # æ–¹æ³•2: syndication API
    print("  å°è¯• syndication API...", file=sys.stderr)
    data = fetch_via_syndication(tweet_id)
    if data and data.get("text"):
        print("  âœ… syndication æˆåŠŸ", file=sys.stderr)
        return format_output(data, "syndication"), tweet_id, username

    return {"success": False, "error": "æ‰€æœ‰æŠ“å–æ–¹å¼å‡å¤±è´¥"}, tweet_id, username


def generate_markdown(result, tweet_id, username, url):
    """ç”Ÿæˆ Markdown æ ¼å¼å†…å®¹"""
    content = result.get("content", {})
    content_type = result.get("type", "tweet")
    
    lines = []
    
    if content_type == "article":
        # X Article é•¿æ–‡ç« 
        title = content.get("title", "Untitled")
        lines.append(f"# {title}")
        lines.append("")
        lines.append(f"> ä½œè€…: **{content.get('author', '')}** (@{content.get('username', '')})")
        lines.append(f"> å‘å¸ƒæ—¶é—´: {content.get('created_at', '')}")
        if content.get('modified_at'):
            lines.append(f"> ä¿®æ”¹æ—¶é—´: {content.get('modified_at', '')}")
        lines.append(f"> åŸæ–‡é“¾æ¥: {url}")
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # å°é¢å›¾
        if content.get("cover_image"):
            lines.append(f"![å°é¢]({content.get('cover_image')})")
            lines.append("")
        
        # æ­£æ–‡
        if content.get("full_text"):
            lines.append(content.get("full_text"))
        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("## äº’åŠ¨æ•°æ®")
        lines.append("")
        lines.append(f"- â¤ï¸ ç‚¹èµ: {content.get('likes', 0):,}")
        lines.append(f"- ğŸ” è½¬å‘: {content.get('retweets', 0):,}")
        lines.append(f"- ğŸ‘€ æµè§ˆ: {content.get('views', 0):,}")
        lines.append(f"- ğŸ”– ä¹¦ç­¾: {content.get('bookmarks', 0):,}")
    else:
        # æ™®é€šæ¨æ–‡
        lines.append(f"# @{content.get('username', '')} çš„æ¨æ–‡")
        lines.append("")
        lines.append(f"> ä½œè€…: **{content.get('author', '')}** (@{content.get('username', '')})")
        lines.append(f"> å‘å¸ƒæ—¶é—´: {content.get('created_at', '')}")
        lines.append(f"> åŸæ–‡é“¾æ¥: {url}")
        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append(content.get("text", ""))
        lines.append("")
        
        # åª’ä½“
        media = content.get("media", [])
        if media:
            lines.append("## åª’ä½“")
            lines.append("")
            for i, m in enumerate(media, 1):
                lines.append(f"![åª’ä½“{i}]({m})")
            lines.append("")
        
        lines.append("---")
        lines.append("")
        lines.append("## äº’åŠ¨æ•°æ®")
        lines.append("")
        lines.append(f"- â¤ï¸ ç‚¹èµ: {content.get('likes', 0):,}")
        lines.append(f"- ğŸ” è½¬å‘: {content.get('retweets', 0):,}")
        lines.append(f"- ğŸ‘€ æµè§ˆ: {content.get('views', 0):,}")
        lines.append(f"- ğŸ’¬ å›å¤: {content.get('replies', 0):,}")
    
    return "\n".join(lines)


def save_markdown(markdown_content, tweet_id, username):
    """ä¿å­˜ Markdown æ–‡ä»¶"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{username}_{tweet_id}_{timestamp}.md"
    
    with open(filename, "w", encoding="utf-8") as f:
        f.write(markdown_content)
    
    return filename

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python fetch_x.py <x_url> [--save-md]")
        print("ç¤ºä¾‹: python fetch_x.py https://x.com/elonmusk/status/123456789")
        print("      python fetch_x.py https://x.com/elonmusk/status/123456789 --save-md")
        sys.exit(1)

    url = sys.argv[1]
    auto_save = "--save-md" in sys.argv
    
    result, tweet_id, username = fetch_tweet(url)

    # è¾“å‡º JSON ç»“æœ
    print(json.dumps(result, ensure_ascii=False, indent=2))
    
    # å¦‚æœæŠ“å–æˆåŠŸï¼Œè¯¢é—®æ˜¯å¦ä¿å­˜ Markdown
    if result.get("success"):
        if auto_save:
            # ä½¿ç”¨ --save-md å‚æ•°æ—¶ç›´æ¥ä¿å­˜
            save_md = True
        else:
            # äº¤äº’å¼è¯¢é—®
            print("\n" + "="*50, file=sys.stderr)
            response = input("ğŸ“ æ˜¯å¦ä¿å­˜ä¸º Markdown æ–‡ä»¶ï¼Ÿ(y/n): ").strip().lower()
            save_md = response in ['y', 'yes', 'æ˜¯']
        
        if save_md:
            markdown_content = generate_markdown(result, tweet_id, username, url)
            filename = save_markdown(markdown_content, tweet_id, username)
            print(f"âœ… å·²ä¿å­˜åˆ°: {filename}", file=sys.stderr)

if __name__ == "__main__":
    main()
